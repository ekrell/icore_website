# iCORE Newsletter – 2023/07/20

![logo](../img/logo_plain_sm.jpg)

The iCORE newsletter highlights events and information related to the [innovation in COmputing REsearch (iCORE) lab](https://icore.tamucc.edu/),
as well as the broader GSCS/CS programs at Texas A&M University - Corpus Christi and whatever else might interest that community.
If you have any news or resources you would like to share, send an email to [Evan Krell](https://scholar.google.com/citations?user=jLuwYGAAAAAJ&hl=en) (ekrell@islander.tamucc.edu).

[See past newsletters.](https://github.com/ekrell/icore_website/tree/main/news)

## Welcome

![Evan and Mahmoud at AgriLife, among the cotton field](../img/P7190986_small.jpg)

Evan Krell with iCORE's #1 farmer Mahmoud Eldefrawy. We are among the cotton fields at [AgriLife](https://agrilifeextension.tamu.edu/). Mahmoud's research involves deep learning and computer vision for estimating crop yield.  

## iCORE Meetings

**[iCORE Teams meeting link](https://teams.microsoft.com/l/meetup-join/19%3Ameeting_MDdlZDBiMTgtYzVjNS00YjhhLWE5OTctY2Y5YzMyYTljNzU5%40thread.v2/0?context=%7B%22Tid%22%3A%2234cbfaf1-67a6-4781-a9ca-514eb2550b66%22%2C%22Oid%22%3A%22994c008b-0707-4f3c-8ac0-73b65e733430%22%2C%22MessageId%22%3A%220%22%7D)**

### Last meeting: July 20, noon-1:30pm

- There were only four of us at the meeting so we changed location to Coffee Waves.
- The purpose of doing so was to enjoy drinks at Dr. King's expense.
- We had general updates and accidently met up with Waylon Collins from the National Weather Service.
- Dr. King gave us a lesson in stone-age gaming history by talking about the ASCII-based network games he used to play.

### Next meeting: August 3, noon-1:30pm

- Dr. King will be out. So we'll have tea.
- There will tea sandwiches, snacks, etc.
- More details soon. 

## Recent Events

#### Evan's Visit to AgriLife

Yesterday (7/19), Evan Krell was given a tour of AgriLife for two purposes: (1) to get some photos of where Mahmoud does his research for the iCORE newsletter, and (2) for a secret mission related to the cotton that is quite likely to get Evan in trouble. Evan is going against Wen Zhong's expert advise to do something stupid. [A full album of AgriLife photos can be found here](https://photos.app.goo.gl/iUD9oxAUPnUG7gns6). 

For Mahmoud's research, it is very important to obtain accurate ground truth data regarding the yield of the cotton harvest. So, tending to the crops at AgriLife and keeping the cotton free of weeds has become nearly his full-time occupation. 

![The cotton field](../img/P7190967_small.jpg)

Here are some rows of cotton. For a while, Mahmoud was working on a vehicle that would navigate between the rows to obtain imagery to create point clouds. 

![The cotton flower](../img/P7190977_small.jpg)

In its earliest stage, the cotton flower is pink. Soon it will turn yellow. 

![The cotton ball](../img/P7190970_small.jpg)

The cotton ball is in fact the plant's fruit since it surrounds the seed. 

![Drying ovens](../img/P7191003_small.jpg)  

Ovens are used to dry out the cotton by maintaining a relatively low heat for many days. 

![Picking a weed](../img/P7190981_small.jpg)

My contribution to AgriLife's cotton-growing program: I picked a weed. 

![Lei & Mahmoud](../img/P7190960_small.jpg)

Lei Zhao and Mahmoud: computer scientists toiling away under the summer sun. 

#### Recent Defenses 

**Wen Zhang**







**Carly Stanton**


**Pratikshya Regmi**



**Jose Luis Landivar**




## Upcoming Events

### Mel Wilson Reyes' AI2ES Presentation

- **Title:** Visibility Estimation from Camera Images Using Deep Learning
- **Where:** NRC 1232 Conference Room
- **When:** 1:15 PM - 2:45 PM

**Abstract:**

Atmospheric visibility is an important and complex meteorological variable that directly affects safe and reliable transportation. Specifically, declining visibility can pose an increased risk to automotive, aviation, and maritime traffic and operations. Traditional visibility sensors, e.g., those of the Automated Surface Observing Systems (ASOS) network, are costly and designed for air traffic use, thus these visibility sensor networks have limited coverage state-wide. In contrast, camera footage is highly available, accessible, and fairly inexpensive. While it is possible to construct a model that detects a visibility measure for a single camera or location, this type of model is not generalizable to new locations with varying physical features or different fields of view. I propose a comparative visibility model that is generalizable solution to new locations. I train a convolutional neural network (CNN) that compares a query image and a reference image that originate from the same cameras and determines the degree to which the query image is less visible than the reference image. A query image from a new camera can then be compared to a set of reference images with known visibility distances from the same camera. These comparisons can then be used to infer the query image’s underlying visibility distance. In addition, a model can be trained using a set of locations that have different maximum visibility distances, fields of view, and physical characteristics. The resulting comparative model can generalize to novel sites. When combined with a small number of calibrated reference images for a given site, visibility distances can be accurately estimated from previously unseen query images. Results from a large combined NYSM/ASOS data set show that the models learned using the proposed method are able to generalize to new locations. The approach is successful in the comparative case and the numerical visibility prediction case. With these outcomes, the model is also able to effectively monitor visibility over time.

## Del Mar Kid's Code Summer Camp

- If interested, talk to Dr. Tissot



